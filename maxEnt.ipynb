{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bfe862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - GCC 13.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BUILD_TYPE=Release, COMMIT_SHA=3443627e078deb813ae37f7182d41a802bd05ac4, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS=-O3 -march=native -mfma -mavx -mavx2 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -DC10_NODEPRECATED -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-dangling-reference -Wno-error=dangling-reference -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.8.0, USE_CUDA=0, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EIGEN_FOR_BLAS=ON, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=OFF, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "2.8.0a0+git3443627\n"
     ]
    }
   ],
   "source": [
    "### IMPORT AND CONFIGURATION/UTILITIES FUNCTION\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\", output_hidden_states=True, output_attentions=True, attn_implementation=\"eager\")\n",
    "\n",
    "def get_tokens_prob(x, embeddings, k=5):\n",
    "    # Compute the similarity between the token and all the tokens in the vocabulary, then applies softmax\n",
    "    prob = torch.softmax(torch.matmul(x, embeddings.T), dim=-1)\n",
    "\n",
    "    # Get the top k tokens\n",
    "    top = torch.topk(prob, k=k)\n",
    "    idxs = top.indices\n",
    "    tokens = [tokenizer.decode(idx) for idx in idxs]\n",
    "    return top.values, idxs, tokens\n",
    "\n",
    "print(torch.__config__.show())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537573a0",
   "metadata": {},
   "source": [
    "## Applying MaxEnt to explore the inner working of GPT2 \n",
    "\n",
    "Let $\\vec e_1, \\vec e_2, \\dots, \\vec e_{n+1}$ be the tokens in the input prompt. We'd like to determine:\n",
    "$$\n",
    "p(\\vec x | \\vec e_1, \\vec e_2, \\dots, \\vec e_n)\n",
    "$$\n",
    "which is essentially what the transformer computes after $12$ repetitions of the ATTN+FFNN mechanism. In principle, since the action of the transformer (_the dynamical rule_) is known, one could potentially figure out exactly the resulting pdf in the vocabulary space. This is however analytically infeasible, since the transformer is made of several non linear layers (FFNN) and the dynamics is allegedely extremely complicated. Thus, analoguosly to what we do in stat mech, we hope our system is ergodic and try to build a statistical description on top of the whole embedding space.\n",
    "\n",
    " In particular, we resort to the __MaxEnt principle__ to compute (analytically or not) the final conditioned pdf. Note that we do have the \"correct\" pdf $p(\\vec x | \\vec e_1, \\vec e_2, \\dots, \\vec e_n)$ and the most probable token $e_{n+1}$. We just want to see whether, upon applying MaxEnt with the right constraints, we can obtain something similar to the distribution computed by the transformer\n",
    "\n",
    " ### Bolztmann-like approach\n",
    " The Shannon entropy functional $S$ reads:\n",
    "\n",
    "$$\n",
    "S[p] = -k \\int d^D x \\> p(\\vec x) \\ln p(\\vec x) \n",
    "$$\n",
    "the first constraint is, obviously, the normalization $ \\int d^D x \\> p(\\vec x) = 1 $  (_over what? For now, I've normalized everything, so on the hypercube_)\n",
    "\n",
    "In this first paragraph, we apply the following constraint:\n",
    "$$\n",
    "\\langle \\vec x \\rangle = \\vec{e}_{n+1}\n",
    "$$\n",
    "because we do have the \"right\" next token (again, we don't want to perform prediction here with the maxEnt. We just wish to see if the resulting pdf has some similarities with the one suggested by the maximization of $S$).\n",
    "\n",
    "This leads to an analytic form for $p(\\vec x | \\vec e_1, \\vec e_2, \\dots, \\vec e_n)$:\n",
    "$$\n",
    "p(\\vec x | \\vec e_1, \\vec e_2, \\dots, \\vec e_n) = p(\\vec x) = \\frac{1}{Z} \\exp(\\vec \\mu \\cdot \\vec x)\n",
    "$$\n",
    "with $Z =\\prod_{i=1}^{D} \\frac{2 sinh(\\mu_i)}{\\mu_i}$ and the vector $\\mu$ (the lagrange multiplier) is such that:\n",
    "$$\n",
    "\\vec e_{n+1} = -\\frac{1}{\\vec\\mu} + \\frac{1}{\\tanh(\\vec\\mu)} \\Longleftrightarrow \\vec\\mu = f(\\vec e_{n+1})\n",
    "$$\n",
    "\n",
    "Practically speaking, we have built a pdf Boltzmann-like where the expected value has to be the correct next token and the mode (the vector in the embedding space that maximizes the probability) is precisely $\\vec \\mu$. Let's see what $\\vec \\mu$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec612f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a multipurpose function that can be used to extract the probability density function of the next token and will be useful later.\n",
    "def GPT2extractPDFLastToken(prompt, lengthPrediction=5):\n",
    "    \"\"\"\n",
    "    This function takes a prompt masking the last word and returns the probability density function as computed by GPT 2 of what was the masked token.\n",
    "    Additionally, it returns the attention vector and the embedding matrix of the masked sequence of tokens, if needed.\n",
    "    :param prompt: The input prompt\n",
    "    :return: The probability density function of the next token\n",
    "    \"\"\"\n",
    "    prompt = ' '.join(prompt.split()[:-1])\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    n = len(inputs[\"input_ids\"][0]) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # run the transfomer inference\n",
    "        outputs = model(**inputs)\n",
    "        hidden_states = outputs.hidden_states\n",
    "        # get the hidden states (i.e. matrices of the last layer)\n",
    "    layers = hidden_states[1:]\n",
    "\n",
    "    # the next token is the last one in the last layer\n",
    "    nextToken = (layers[-1][0])[-1]\n",
    "    # project it into the vocabulary space and build a pdf on top of it using softmax\n",
    "    prob, idxs, tokens = get_tokens_prob(nextToken, model.wte.weight.data,lengthPrediction)\n",
    "    return prob, idxs, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc2238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> logp = 0.28: [' Galile'], idx = 32422\n",
      " -> logp = 2.29: ['.'], idx = 13\n",
      " -> logp = 3.12: [' and'], idx = 290\n",
      " -> logp = 3.55: [','], idx = 11\n",
      " -> logp = 5.17: ['.\"'], idx = 526\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I'm an Italian physicist who lived in Padua. I am known for my work in the field of optics and astronomy. \" \\\n",
    "        \"I was born in 1564 and died in 1642. My name is Galileo Galilei\"\n",
    "prob, idxs, tokens = GPT2extractPDFLastToken(prompt)\n",
    "for p, idx, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> logp = {-torch.log(p):.2f}: ['{token}'], idx = {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3cb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.9999999403953552\n",
      "Succesfully computed mu vector.\n",
      "It represents the direction of maximum probability; projecting mu over the vocabolary we get: \n",
      "\n",
      " -> logp = 7.14: [' Galile'], idx = 32422\n",
      " -> logp = 9.71: [' Canaver'], idx = 46858\n",
      " -> logp = 9.83: ['Palest'], idx = 32570\n",
      " -> logp = 9.84: [' Galileo'], idx = 45860\n",
      " -> logp = 9.86: [' Presbyter'], idx = 40507\n",
      " -> logp = 9.87: [' Palest'], idx = 5480\n",
      " -> logp = 9.90: [' Jude'], idx = 30044\n",
      " -> logp = 9.91: [' horizont'], idx = 13736\n",
      "\n",
      "As expected, it points practically with certainty to the right expected token\n"
     ]
    }
   ],
   "source": [
    "#This is the function we want to solve\n",
    "def f(x,k):\n",
    "    return 1 / np.tanh(x) - 1 / x - k\n",
    "\n",
    "# We need to constraint the mean value of the distribution to be equal to the expected value of the token\n",
    "tokenExpected = model.wte.weight.data[idxs[0]]      # extracted from above\n",
    "\n",
    "# Solve it component by component\n",
    "mu = torch.tensor(np.zeros( model.wte.weight.data.shape[1]), dtype=torch.float32)\n",
    "\n",
    "for i,d in enumerate(tokenExpected):\n",
    "    xi = d.item()\n",
    "    mu_i = fsolve(f, 1, args=(xi))\n",
    "    mu[i] = (mu_i.item())\n",
    "mu = mu / torch.norm(mu)  # Normalize the vector? Does it make sense?\n",
    "print(f\"mu = {torch.norm(mu)}\")\n",
    "print(f\"Succesfully computed mu vector.\")\n",
    "print(\"It represents the direction of maximum probability; projecting mu over the vocabolary we get: \\n\")\n",
    "# mu should be the direction of maximum probability (mode). At what does it point to?\n",
    "prob, idxs, tokens = get_tokens_prob(mu, model.wte.weight.data, 8)\n",
    "for p, idx, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> logp = {-torch.log(p):.2f}: ['{token}'], idx = {idx}\")\n",
    "\n",
    "print(\"\\nAs expected, it points practically with certainty to the right expected token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5da8c",
   "metadata": {},
   "source": [
    "This is a boring result. We did get the right token but this was, of course, by no surprise since we cooked that information into the pdf. In fact, the other tokens suggested by the Boltzmann model were probably related to the word \"Galilea\" (Palest, Jude, Canaver). Since we didn't used the previous token, we lost all the context contained by the whole sequence of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3b7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengthQueue = 15\n",
    "prob, idxs, tokens = get_tokens_prob(embeddings[idxs[0]]  , lengthQueue)\n",
    "\n",
    "def logprobBoltzmann(x):\n",
    "    unnorm = np.dot(x, mu)\n",
    "    logterms = np.log( 2 * np.sinh(mu.numpy()) /  mu.numpy() )\n",
    "    logZ = np.sum(logterms)\n",
    "    logZdiscrete = np.sum(np.exp(np.dot(embeddings, mu)))\n",
    "    logZdiscrete = np.log(logZdiscrete)\n",
    "    return unnorm - logZdiscrete\n",
    "\n",
    "probBolztmann = np.zeros(lengthQueue)   \n",
    "for k,tkn in enumerate(embeddings[idxs]):\n",
    "    #print(logprobBoltzmann(tkn.numpy()), -torch.log(prob[k]).item(), tokens[k])\n",
    "    probBolztmann[k] = logprobBoltzmann(tkn.numpy())\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(16, 5))\n",
    "ax[1].plot(-probBolztmann, label=\"Boltzmann model\", c = \"orange\")\n",
    "ax[1].scatter(range(len(probBolztmann)), -probBolztmann, color=\"orange\", edgecolor=\"black\", s=40)\n",
    "ax[0].plot(-torch.log(prob).numpy(), label=\"GPT2 probabilities\")\n",
    "ax[0].scatter(range(len(prob)), -torch.log(prob).numpy(), color=\"blue\", edgecolor=\"black\", s=40)\n",
    "ax[0].set_title(\"Negative log probability of the most probable token (according to GPT2) \\n In descending order\")\n",
    "ax[0].set_xlabel(\"Token\")\n",
    "ax[0].set_ylabel(\"Log probability\")\n",
    "ax[0].legend()\n",
    "ax[1].set_xlabel(\"Token\")\n",
    "ax[1].set_ylabel(\"Log probability\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Negative log probability of the most probable token (according to Boltzmann pdf) \\n Same token as ranked by GPT2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed2a02",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Nota che per come funziona il transformer, la distribuzione finale deve essere alla Bolztmann -> tutto ciò per dire che è compatibile con un discorso maxent e quindi ci motiva quanto meno a procedere\n",
    "\n",
    "\n",
    "## Using the attention matrix - continuous approach\n",
    "\n",
    "The previous approach was clearly extremely simple and trivial, lacking precious information that we have on the resulting pdf (in fact, we didn't use the previous tokens $\\{e_i\\}$). Let us think of a new constraint. Since the dot product in the embedding space (upon normalization) is somehow related to the similarities between tokens, we may wish to constrain:\n",
    "$$ \n",
    "\\langle \\vec x \\cdot \\vec e_i \\rangle = something, \\>\\> \\forall \\vec e_i\n",
    "$$\n",
    "Since the transfomer provides us with attention matrices, why don't use those quantities to constrain our entropy. In particular, if $\\hat A$ is the $(n+1) \\times (n+1)$ attention matrix at the end of \n",
    "\n",
    "N.B. Again, this is kinda stupid, since in order to compute the attention matrix we need to know before-hand the next token, thus making this approach pretty useless. We can rephrase it in this way: given that someone from above gifts us with the correlation that the next token has with the previous ones but not the token itself, then we can build a MaxEnt model from that scarce information. A posteriori, we can see whether GPT's distribution is similar to the one produced with this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1345878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "\n",
    "def getEA(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    n = len(inputs[\"input_ids\"][0]) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    attentions = outputs.attentions\n",
    "\n",
    "    lastStepAttentionMatrices = attentions[0][0]\n",
    "    vectorA = torch.tensor( np.zeros(n-1) )              # Not the last token (itself w/ itself)\n",
    "    #iterate on the heads\n",
    "    for head in range(12):\n",
    "        attentionHead = lastStepAttentionMatrices[head]\n",
    "        column = attentionHead[-1,:]   # last row\n",
    "        column = column[:-1]           # remove the last element (autocorrelation)\n",
    "        # renormalize\n",
    "        column = column/(torch.sum(column))\n",
    "        vectorA = (vectorA + column)\n",
    "    # Normalization step\n",
    "    vectorA = vectorA / 12\n",
    "    #print(\"The vector A is: \", vectorA)\n",
    "\n",
    "    embeddings = model.wte.weight.data\n",
    "    T = torch.nn.functional.one_hot(inputs.input_ids[0], num_classes=embeddings.shape[0]).float()\n",
    "    E = torch.matmul(T,embeddings)\n",
    "    E = E[:-1,:]                                         # I don't want the last (masked) token   \n",
    "    return vectorA, E\n",
    "\n",
    "# f function (to improve stability, Taylor expansion around 0)\n",
    "def f(z, tol = 0.001):\n",
    "    z = np.asarray(z) \n",
    "    result = np.empty_like(z, dtype=float)\n",
    "    # when z is small, we use a Taylor expansion (to avoid numerical instability)\n",
    "    z_small = z[np.abs(z) < tol]\n",
    "    result[np.abs(z) < tol] = (-1/3)*z_small + (2/45)*z_small**3 - (17/945)*z_small**5\n",
    "    # when z is big, we use the original function\n",
    "    z_big = z[np.abs(z) > tol]\n",
    "    result[np.abs(z) > tol] = - 1 / np.tanh(z_big) + 1 / z_big\n",
    "    return result\n",
    "\n",
    "# This is the system we want to solve\n",
    "def system(x, E, A):\n",
    "    z = np.dot(E.T, x)     \n",
    "    fz = f(z)        \n",
    "    fz = fz.reshape(-1, 1)     \n",
    "    v = E @ fz\n",
    "    v = v.reshape(-1)      \n",
    "    return v - A      \n",
    "\n",
    "def solveMu(E, vectorA, amplificationAttention=1):\n",
    "    x0 = np.random.random(len(vectorA))\n",
    "    x0 = 0.1*x0 \n",
    "\n",
    "    res = least_squares(\n",
    "        system, x0,\n",
    "        args=(E.numpy(), amplificationAttention * vectorA.numpy()),\n",
    "        method=\"trf\",       # trust-region reflective\n",
    "        max_nfev=1000,      # max iterations\n",
    "        xtol=1e-8,          # precision\n",
    "        verbose=0\n",
    "    )\n",
    "    if not res.success:\n",
    "        print(\" least_squares non ha convergenza:\", res.message)\n",
    "    return res.x\n",
    "\n",
    "def computeZ(a, V):\n",
    "    Z = 0\n",
    "    for token in V:\n",
    "        dot_product = np.dot(token, a)\n",
    "        exp_value = np.exp(dot_product)\n",
    "        Z += exp_value\n",
    "    #print(\"Z = \", Z ,\"**********\")\n",
    "    return Z\n",
    "\n",
    "def computeLogZ(a, V):\n",
    "    s = torch.sum(a * V, axis=1)  # shape: (n,)\n",
    "    a = torch.min(s)\n",
    "    return -a + torch.log(torch.sum(torch.exp(-(s - a))))\n",
    "\n",
    "def createPDFoverVocabulary(a, Z, lengthQueue = 10):\n",
    "    \"\"\"\n",
    "    This function creates a probability density function over the vocabulary using the mu vector and the embeddings.\n",
    "    :param mu: The mu vector\n",
    "    :param V: The embeddings matrix\n",
    "    :return: The probability density function over the vocabulary\n",
    "    \"\"\"\n",
    "    embeddings = model.wte.weight.data\n",
    "    logProb = np.zeros(len(embeddings))\n",
    "    for i,tkn in enumerate(embeddings):\n",
    "        dot_product = np.dot(tkn, a)\n",
    "        logProb[i] = -dot_product + np.log(Z)\n",
    "        \n",
    "    sorted_indices = np.argsort(logProb)\n",
    "    id_to_token = {v: k for k, v in tokenizer.encoder.items()}\n",
    "    for j in range(lengthQueue):\n",
    "        decoded_token = tokenizer.decode([sorted_indices[j]])\n",
    "        print(f\" -> -logP: { logProb[sorted_indices[j]]:.4f}, [{decoded_token}], idx = {sorted_indices[j]}\")\n",
    "\n",
    "\n",
    "def gpt2_tokens(text):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    tokens = [tokenizer.decode([token_id]) for token_id in input_ids]\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a380e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', ' Mon', 'a', ' Lisa', ' is', ' a', ' world', '-', 'famous', ' painting', ' by', ' Leonardo', ' da', ' Vin', 'ci', ',', ' created', ' in', ' the', ' early', ' 16', 'th', ' century', '.', ' It', ' is', ' housed', ' in', ' the', ' Lou', 'vre', ' Museum', ' in', ' Paris', ' and', ' is', ' known', ' for', ' its', ' enigmatic', ' expression', ' and', ' detailed', ' background', '.', ' The', ' painting', ' is', ' considered', ' a', ' masterpiece', ' of', ' the', ' Italian', ' Renaissance']\n",
      "Masking the last token (\"Renaissance\"), GPT2 would have predicted:\n",
      " -> -logP = 5.76: ['theless'], idx = 9603\n",
      " -> -logP = 5.90: ['soDeliveryDate'], idx = 39811\n",
      " -> -logP = 5.98: [' \"$:/'], idx = 32047\n",
      " -> -logP = 5.98: ['SPONSORED'], idx = 37190\n",
      " -> -logP = 6.11: ['interstitial'], idx = 29446\n",
      " -> -logP = 6.29: ['entimes'], idx = 43598\n",
      " -> -logP = 6.43: [' ‎'], idx = 24398\n",
      " -> -logP = 6.43: ['inventoryQuantity'], idx = 39756\n",
      " -> -logP = 6.44: ['manship'], idx = 25428\n",
      " -> -logP = 6.45: [' ILCS'], idx = 36169\n",
      "\n",
      "A MaxEnt approach yields:\n",
      "For the mean value (MAXENT):\n",
      " -> 10.17: ' Italian'\n",
      " -> 10.24: 'Italian'\n",
      " -> 10.38: ' Italians'\n",
      " -> 10.40: ' Italy'\n",
      " -> 10.40: 'Italy'\n",
      "For the mode value (MAXENT):\n",
      " -> 8.85: ' Italian'\n",
      " -> 9.06: 'Italian'\n",
      " -> 9.49: ' Italians'\n",
      " -> 9.56: ' Italy'\n",
      " -> 9.57: 'Italy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6693/568661031.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prob, idxs, tokens = get_tokens_prob(torch.tensor(x_mode, dtype = torch.float),  model.wte.weight.data, 5)\n"
     ]
    }
   ],
   "source": [
    "# A bunch of test prompts\n",
    "prompt = \"--- - - - ---- - - - ----p''''' -\"\n",
    "prompt = \"Mount Everest is the tallest mountain on Earth, located in the Himalayas on the border between Nepal and China\"\n",
    "prompt = \"The year is 2194, and humanity no longer lives on Earth. After the Collapse, we fled to floating arcologies orbiting the gas giants. Every child knows the stories of our homeworld, but none of us have seen a tree, felt rain, or walked on\"\n",
    "prompt = \"The american flag is white, red and blue. The flag has 13 stripes and 50 stars\"\n",
    "prompt = \"The Great Wall of China is a series of fortifications built to protect ancient Chinese states from invasions. It stretches over 13,000 miles and is one of the most iconic structures in the world. The wall was built over several dynasties, with the earliest sections dating back to the 7th century BC\"\n",
    "prompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I made groundbreaking contributions not only to relativity but also to quantum mechanics, statistical mechanics, and cosmology. \" \\\n",
    "\"My famous equation, E=mc², has become one of the most well-known formulas in the world. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect, which helped establish quantum theory. \" \\\n",
    "\"Throughout my life, I advocated for civil rights, pacifism, and Zionism, and I was known for my humanitarian views. \" \\\n",
    "\"I spent my later years in the United States, working at the Institute for Advanced Study in Princeton. \" \\\n",
    "\"I was born in 1879 and died in 1955. My name is Albert Einstein\"\n",
    "prompt = \"DNA, or deoxyribonucleic acid, is the molecule that carries genetic instructions in all living organisms. It is composed of four nucleotide bases: adenine, thymine, cytosine, and guanine. These bases form sequences that determine traits and biological functions. The structure of DNA is a double helix, with two strands winding around each other, held together by complementary base pairing—adenine pairs with thymine, and cytosine with guanine. This configuration ensures accurate replication during cell division. Mutations, or changes in the DNA sequence, can lead to variations in traits, some of which may result in genetic disorders or evolutionary advantages.DNA replication and transcription are essential processes that convert genetic information into proteins, which perform vital structural and functional roles in the body. Understanding DNA has revolutionized fields such as medicine, forensic science, and biotechnology, enabling breakthroughs like gene editing and personalized treatments\"\n",
    "prompt = \"The american flag is white, red and blue\"\n",
    "prompt = \"DNA, or deoxyribonucleic acid, is the molecule that carries genetic instructions in all living organisms. It is composed of four nucleotide bases: adenine, thymine, cytosine, and guanine. These bases form sequences that determine traits and biological functions\"\n",
    "prompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect.\" \\\n",
    "\" I was born in 1879 and died in 1955. My name is Albert Einstein\"\n",
    "prompt = \"I'm an Italian physicist who lived in Padua. I am known for my work in the field of optics and astronomy. \" \\\n",
    "        \"I was born in 1564 and died in 1642. My name is Galileo Galilei\"\n",
    "prompt = \"The Mona Lisa is a world-famous painting by Leonardo da Vinci, created in the early 16th century. It is housed in the Louvre Museum in Paris and is known for its enigmatic expression and detailed background. The painting is considered a masterpiece of the Italian Renaissance\"\n",
    "\n",
    "prob, idxs, tokens = GPT2extractPDFLastToken(prompt, 10)\n",
    "print(gpt2_tokens(prompt))\n",
    "print(\"Masking the last token (\\\"\" , ''.join(prompt.split()[-1]), \"\\\"), GPT2 would have predicted:\", sep = \"\")\n",
    "for p, idx, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> -logP = {-torch.log(p):.2f}: ['{token}'], idx = {idx}\")\n",
    "\n",
    "\n",
    "model.wte.weight.data = torch.nn.functional.normalize(model.wte.weight.data, p=2, dim = 1)\n",
    "# Get the attention vector and the embedding matrix\n",
    "vectorA, E = getEA(prompt)\n",
    "# Let's solve for mu, now that we have the attention vector and the embedding matrix\n",
    "amplificationAttention = 4\n",
    "mu = solveMu(E, vectorA, amplificationAttention)\n",
    "Z = computeZ(-E.T @ mu, model.wte.weight.data)\n",
    "# given mu, we can compute the mean and the mode according to the maxent model\n",
    "x_avg, x_mode = f(E.T @ mu), -E.T @ mu\n",
    "\n",
    "\n",
    "print(\"\\nA MaxEnt approach yields:\")\n",
    "print(\"For the mean value (MAXENT):\")\n",
    "prob, idxs, tokens = get_tokens_prob(torch.tensor(x_avg, dtype = torch.float), model.wte.weight.data, 5)\n",
    "for p, _, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n",
    "\n",
    "print(\"For the mode value (MAXENT):\")\n",
    "prob, idxs, tokens = get_tokens_prob(torch.tensor(x_mode, dtype = torch.float),  model.wte.weight.data, 5)\n",
    "for p, _, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n",
    "\n",
    "#print(\"\\nMaxEnt would have predicted the following tokens:\")\n",
    "#createPDFoverVocabulary(-E.T @ mu, Z, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7a719",
   "metadata": {},
   "source": [
    "## Discretization\n",
    "Let us now discretize the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a13a1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from scipy.special import softmax\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\", output_hidden_states=True, output_attentions=True, attn_implementation=\"eager\")\n",
    "\n",
    "def getEA(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    n = len(inputs[\"input_ids\"][0]) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # extract the attentions matrices\n",
    "    attentions = outputs.attentions\n",
    "    \n",
    "    chosenLayer = 0\n",
    "    lastStepAttentionMatrices = attentions[chosenLayer][0]\n",
    "    vectorA = torch.tensor( np.zeros(n-1) )              # Not the last token (itself w/ itself)\n",
    "    #iterate on the heads\n",
    "    for head in range(12):\n",
    "        attentionHead = lastStepAttentionMatrices[head]\n",
    "        column = attentionHead[-1,:]   # last row\n",
    "        column = column[:-1]           # remove the last element (autocorrelation)\n",
    "        column = column/(torch.sum(column))\n",
    "        vectorA = (vectorA + column)\n",
    "    # Normalization step\n",
    "    vectorA = vectorA / 12\n",
    "    #print(\"The vector A is: \", vectorA)\n",
    "\n",
    "    T = torch.nn.functional.one_hot(inputs.input_ids[0], num_classes=embeddings.shape[0]).float()\n",
    "    E = torch.matmul(T,embeddings)\n",
    "    #E = E / np.linalg.norm(E, axis=0, keepdims=True)     # Normalize again by row\n",
    "    E = E[:-1,:]                                         # I don't want the last (masked) token   \n",
    "    return vectorA, E\n",
    "\n",
    "def loss(mu, Om, A):\n",
    "    ZT_mu = torch.matmul(Om.T, mu) \n",
    "    s = torch.softmax(-ZT_mu, dim=0)  \n",
    "    Zs = torch.matmul(Om, s)  \n",
    "    return torch.sum((Zs - A)**2)\n",
    "\n",
    "def solveMuDiscrete2(E, embeddings, A, lr=0.05, max_iter=1000, verbose=True):\n",
    "    OMEGA = torch.matmul(E, embeddings.T)\n",
    "    \n",
    "    correctEinstein = embeddings[tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\" Galile\"))].numpy()\n",
    "    correctEinstein.shape = (768,)\n",
    "    print(correctEinstein.shape, \"should be (n,)\")\n",
    "    x = np.linalg.pinv(E.T) @ correctEinstein\n",
    "\n",
    "    mu = torch.nn.Parameter(torch.tensor(x, dtype=torch.float32, requires_grad=True))\n",
    "    optimizer = torch.optim.Adam([mu], lr=lr)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        L = loss(mu, OMEGA, A)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose and i % 50 == 0:\n",
    "            #print(f\"Iter {i}: loss = {L.item():.6f}\")\n",
    "            pass\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Final loss: {L.item():.6f}\")\n",
    "        print(f\"Optimal mu: {mu.detach()}\")\n",
    "        print(\"A should be: \", torch.matmul(OMEGA, torch.softmax(-torch.matmul(OMEGA.T, mu), dim=0)) )\n",
    "        print(\"A as computed with the right mu:\", torch.matmul(OMEGA, torch.softmax(-torch.matmul(OMEGA.T, torch.tensor(x)), dim=0)) )\n",
    "\n",
    "    return mu.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2f518fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) should be (n,)\n",
      "Final loss: 156.775253\n",
      "Optimal mu: tensor([ 2.8029,  1.5693,  0.8656,  0.4880,  1.4544,  1.4284,  1.9235,  0.3555,\n",
      "         2.9166,  1.0807,  0.5696,  1.0092, -1.3021,  1.7459,  0.6763,  2.4579,\n",
      "         2.6053,  0.3555,  0.5842,  3.2383,  0.3917,  2.6559,  0.3936,  0.4900,\n",
      "         0.5696,  1.0092,  0.8125,  2.5209,  0.3555,  4.8606,  2.0147,  0.3936,\n",
      "         1.3688,  0.3555,  5.3335,  0.9769,  0.5696,  1.8284,  1.8446,  0.5095,\n",
      "         0.7014,  1.6791])\n",
      "A should be:  tensor([1.8338, 2.6065, 1.5259, 2.6844, 2.9774, 1.8684, 1.7922, 1.2597, 2.1481,\n",
      "        2.5474, 1.3402, 1.3531, 2.2867, 1.8526, 1.2978, 1.8259, 1.6653, 1.2597,\n",
      "        1.0524, 2.0211, 1.4129, 2.1828, 1.1964, 3.2108, 1.3402, 1.3531, 1.7825,\n",
      "        2.1459, 1.2597, 1.4823, 2.0977, 1.1964, 2.4987, 1.2597, 1.3840, 2.4014,\n",
      "        1.3402, 2.1615, 1.8959, 1.5694, 2.9707, 3.1494], grad_fn=<MvBackward0>)\n",
      "A as computed with the right mu: tensor([2.5193, 3.0843, 1.7930, 2.8499, 3.7782, 2.1867, 2.9676, 1.3859, 2.9549,\n",
      "        3.1703, 1.7485, 1.8122, 2.1832, 2.4174, 1.5966, 2.1390, 2.1339, 1.3859,\n",
      "        1.2965, 2.3663, 1.6214, 3.5774, 1.3562, 3.5895, 1.7485, 1.8122, 2.0875,\n",
      "        3.0326, 1.3859, 2.1225, 2.9727, 1.3562, 3.0925, 1.3859, 2.1407, 3.0159,\n",
      "        1.7485, 2.4229, 2.3382, 1.8919, 3.7759, 3.6680])\n",
      "A is:  tensor([0.1116, 0.0141, 0.0096, 0.0177, 0.0108, 0.0118, 0.0077, 0.0097, 0.0336,\n",
      "        0.0119, 0.0128, 0.0145, 0.0126, 0.0079, 0.0104, 0.0131, 0.0069, 0.0104,\n",
      "        0.0094, 0.0062, 0.0111, 0.0148, 0.0165, 0.0118, 0.0174, 0.0195, 0.0177,\n",
      "        0.0101, 0.0136, 0.0092, 0.0110, 0.0218, 0.0126, 0.0168, 0.0112, 0.0171,\n",
      "        0.0302, 0.0311, 0.0128, 0.0375, 0.0555, 0.2580], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### TEST PANEL\n",
    "prompt = \"I'm an Italian physicist who lived in Padua. I am known for my work in the field of optics and astronomy. \" \\\n",
    "        \"I was born in 1564 and died in 1642. My name is Galileo Galilei\"\n",
    "\n",
    "vectorA, E = getEA(prompt)\n",
    "#vectorA = vectorA * torch.mean(torch.norm(E, dim = 1))   # SI potrebbe fare questa roba qui\n",
    "\n",
    "\n",
    "mu = solveMuDiscrete2(E, embeddings, vectorA)\n",
    "print(\"A is: \", vectorA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding matrix E is of shape: torch.Size([53, 768])\n",
      "The attention vector A is of shape: torch.Size([53])\n",
      "Success: True\n",
      "mu ottimo: [ 1.023381   -2.9592173  -5.206721   -2.0732296   2.5953646  -0.9638976\n",
      " -2.856685    2.278399   -1.2299044  -4.0165873  -2.4396253  -3.2346785\n",
      " -6.2767773  -1.3281077  -0.46446112  0.44732043 -0.17959857  0.27987838\n",
      "  0.92262757 -0.48367685 -0.47447097 -2.2126894  -0.8918188   0.02618492\n",
      " -0.30484015 -1.2606374   3.0614607  -1.2606374   0.29027256 -4.7754555\n",
      " -0.46446112 -2.3145423  -0.17959857 -0.8918188  -3.2158034  -1.3152328\n",
      " -5.136659    0.92262757 -0.48367685 -0.47447097  0.9417038  -1.2606374\n",
      " -6.080223   -3.1928399  -3.5324836  -0.90797246 -1.2606374  -1.0050166\n",
      "  0.92262757 -2.852927   -2.8601222   0.7233646  -0.6211818 ]\n",
      "Errore finale: 1563.5901225896453\n",
      "Correct mu: [ 0.5116905  -1.4796087  -2.6033604  -1.0366148   1.2976823  -0.4819488\n",
      " -1.4283425   1.1391995  -0.6149522  -2.0082936  -1.2198126  -1.6173393\n",
      " -3.1383886  -0.66405386 -0.23223056  0.22366022 -0.08979928  0.13993919\n",
      "  0.46131378 -0.24183843 -0.23723549 -1.1063447  -0.4459094   0.01309246\n",
      " -0.15242007 -0.6303187   1.5307304  -0.6303187   0.14513628 -2.3877277\n",
      " -0.23223056 -1.1572711  -0.08979928 -0.4459094  -1.6079017  -0.6576164\n",
      " -2.5683296   0.46131378 -0.24183843 -0.23723549  0.4708519  -0.6303187\n",
      " -3.0401115  -1.5964199  -1.7662418  -0.45398623 -0.6303187  -0.5025083\n",
      "  0.46131378 -1.4264635  -1.4300611   0.3616823  -0.3105909 ]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'computeZ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(E\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m@\u001b[39m correctEinsten\n\u001b[1;32m     18\u001b[0m mu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x)\n\u001b[0;32m---> 19\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mcomputeZ\u001b[49m(\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmatmul(E\u001b[38;5;241m.\u001b[39mT, mu), embeddings)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogZ =\u001b[39m\u001b[38;5;124m\"\u001b[39m, Z)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMaxEnt would have predicted the following tokens:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'computeZ' is not defined"
     ]
    }
   ],
   "source": [
    "# A bunch of test prompts\n",
    "prompt = \"I'm an Italian physicist who lived in Padua. I am known for my work in the field of optics and astronomy. \" \\\n",
    "        \"I was born in 1564 and died in 1642. My name is Galileo Galilei\"\n",
    "prompt = \"DNA, or deoxyribonucleic acid, is the molecule that carries genetic instructions in all living organisms. It is composed of four nucleotide bases: adenine, thymine, cytosine, and guanine. These bases form sequences that determine traits and biological functions\"\n",
    "prompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect.\" \\\n",
    "\" I was born in 1879 and died in 1955. My name is Albert Einstein\"\n",
    "\n",
    "# get the embedding matrix\n",
    "embeddings = model.wte.weight.data\n",
    "# Get the attention vector and the embedding matrix\n",
    "vectorA, E = getEA(prompt)\n",
    "## vectorA = vectorA * torch.mean(torch.norm(E, dim = 1))   # SI potrebbe fare questa roba qui\n",
    "\n",
    "# Let's solve for mu, now that we have the attention vector and the embedding matrix\n",
    "mu = solveMuDiscrete2(E.numpy(), embeddings.numpy(), vectorA.numpy()) \n",
    "mu = torch.tensor(mu, dtype=torch.float32) \n",
    "\n",
    "correctEinsten = np.load(\"nextToken.npy\")\n",
    "x = np.linalg.pinv(E.T) @ correctEinsten\n",
    "mu = torch.tensor(x)\n",
    "Z = computeZ(-torch.matmul(E.T, mu), embeddings)\n",
    "print(\"logZ =\", Z)\n",
    "\n",
    "print(\"\\nMaxEnt would have predicted the following tokens:\")\n",
    "createPDFoverVocabulary(-torch.matmul(E.T, mu), Z, 10)\n",
    "\n",
    "print(\"For the mode value (MAXENT):\")\n",
    "prob, idxs, tokens = get_tokens_prob(torch.tensor(-torch.matmul(E.T, mu), dtype = torch.float), 5)\n",
    "for p, _, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> {-torch.log(p):.2f}: '{token}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716ed69",
   "metadata": {},
   "source": [
    "The expected value is not that bad (comments)\n",
    "\n",
    "Nota bene una cosa: qua stiamo ponendo solo $n$ condizioni, ma la distribuzione è su di uno spazio $ d > n $ dimensionale. Dunque stiamo dicendo che il valore medio \\langle x \\rangle non è completamente vincolato (come nel caso precedente), ne stiamo vincolando solo una parte ($n$ componenti, linearmente). Il resto fa maxEnt. Il fatto che qua il valore medio venga decente, almento secondo me, non è scontato (soprattutto se $n$ è molto più piccolo di $d$).\n",
    "\n",
    "Sarebbe carino capire come migliora il modello aggiungendo vincoli, cioè aumentando la dimensione del prompt.\n",
    "\n",
    "----\n",
    "Now without guessing A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f79ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the weights and biases of the attention heads in GPT-2\n",
    "def extractFromGPT2Weights(model, layer:int, head:int):\n",
    "    layer = model.h[layer]\n",
    "    W_qkv = layer.attn.c_attn.weight  \n",
    "    d_model = model.config.n_embd  \n",
    "    W_Q = W_qkv[:d_model, :d_model]     \n",
    "    W_K = W_qkv[:d_model, d_model:2*d_model]\n",
    "    W_V = W_qkv[:d_model, 2*d_model:]\n",
    "\n",
    "    head_dim = d_model // model.config.n_head\n",
    "    i = head  \n",
    "    W_Q_i = W_Q[i * head_dim : (i + 1) * head_dim, :] \n",
    "    W_K_i = W_K[i * head_dim : (i + 1) * head_dim, :]\n",
    "    W_V_i = W_V[i * head_dim : (i + 1) * head_dim, :]\n",
    "    return W_Q_i.detach().numpy(), W_K_i.detach().numpy(), W_V_i.detach().numpy()\n",
    "\n",
    "def extractFromGPT2Bias(model, layer:int, head:int):\n",
    "    layer = model.h[layer]\n",
    "    b_qkv = layer.attn.c_attn.bias  # torch.nn.Parameter\n",
    "    d_model = model.config.n_embd  #. 768\n",
    "    b_Q = b_qkv[:d_model]        # (768,)\n",
    "    b_K = b_qkv[d_model:2*d_model]\n",
    "    b_V = b_qkv[2*d_model:]\n",
    "    \n",
    "    head_dim = d_model // model.config.n_head\n",
    "    i = head  # ad esempio, testa 5\n",
    "    b_Q_i = b_Q[i * head_dim : (i + 1) * head_dim] \n",
    "    b_K_i = b_K[i * head_dim : (i + 1) * head_dim]\n",
    "    b_V_i = b_V[i * head_dim : (i + 1) * head_dim]\n",
    "    return b_Q_i.detach().numpy(), b_K_i.detach().numpy(), b_V_i.detach().numpy()\n",
    "\n",
    "# This function computes the expected activation vector A for the given embedding matrix E, giving us an estimate for the correlations values\n",
    "def computeExpectedA(E):\n",
    "    nHeads = 12\n",
    "    # This will be the best query that resonates with the given keys (old tokens)\n",
    "    bestFitting = torch.tensor( np.zeros(E.shape[1]) , dtype=torch.float32)\n",
    "    # we will essentially average over the heads ...\n",
    "    for head in range(nHeads):\n",
    "        WQ, WK, _ = extractFromGPT2Weights(model, layer = 0, head = head)\n",
    "        bq, bk,_ = extractFromGPT2Bias(model, layer = 0, head = head)\n",
    "        vectors = torch.tensor(np.zeros((E.shape[0],E.shape[1])), dtype=torch.float32)\n",
    "        # and over the tokens !\n",
    "        for i,e in enumerate(E):\n",
    "            vectors[i] = torch.matmul(torch.tensor(WQ.T), torch.tensor(bk)) + torch.matmul(torch.matmul(torch.tensor(WK).T, torch.tensor(WQ)), e)\n",
    "        # sum the vectors by row\n",
    "        bestfittingHead = torch.sum(vectors, dim=0)\n",
    "        # update the general vector\n",
    "        bestFitting = bestFitting + bestfittingHead\n",
    "    bestFitting = bestFitting / torch.mean(bestFitting)  # Normalize the vector?\n",
    "\n",
    "    A = np.zeros(E.shape[0])   # The activation, i.e. the last row vector\n",
    "    for head in range(nHeads):\n",
    "        WQ, WK, _ = extractFromGPT2Weights(model, 0, head)\n",
    "        bq, bk,_ = extractFromGPT2Bias(model, 0, head)\n",
    "        J = np.matmul(WK.T, WQ) \n",
    "        vkq = np.matmul(WK.T , bq)\n",
    "        localA = np.zeros(E.shape[0])\n",
    "        for i, e in enumerate(E):\n",
    "            localA[i] = ( np.matmul(e, np.matmul(J, bestFitting)) + np.matmul(vkq, e) )/8\n",
    "        localA = torch.softmax(torch.tensor(localA), dim=0).numpy()  # Apply softmax to the local activation vector on the row\n",
    "        A = A + localA\n",
    "    A = A / nHeads  # Average over the heads\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42a91601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking the last token (\"Einstein\"), GPT2 would have predicted:\n",
      " -> -logP = 0.96: [' Einstein'], idx = 24572\n",
      " -> -logP = 4.00: [' B'], idx = 347\n",
      " -> -logP = 4.07: [' E'], idx = 412\n",
      " -> -logP = 4.30: [' J'], idx = 449\n",
      " -> -logP = 4.37: [' H'], idx = 367\n",
      " -> -logP = 4.38: [' A'], idx = 317\n",
      " -> -logP = 4.47: [' S'], idx = 311\n",
      " -> -logP = 4.51: [' L'], idx = 406\n",
      " -> -logP = 4.55: ['.'], idx = 13\n",
      " -> -logP = 4.56: [' W'], idx = 370\n",
      "tensor(1.0000, dtype=torch.float64)\n",
      "tensor([0.0572, 0.0024, 0.0021, 0.0194, 0.0023, 0.0141, 0.0109, 0.0251, 0.0026,\n",
      "        0.0062, 0.0031, 0.0027, 0.0060, 0.0024, 0.0018, 0.0051, 0.0019, 0.0119,\n",
      "        0.0028, 0.0014, 0.0019, 0.0050, 0.0039, 0.0013, 0.0013, 0.0018, 0.0108,\n",
      "        0.0019, 0.0016, 0.0017, 0.0038, 0.0034, 0.0022, 0.0053, 0.0033, 0.0023,\n",
      "        0.0024, 0.0026, 0.0059, 0.0027, 0.0013, 0.0046, 0.0035, 0.0021, 0.0020,\n",
      "        0.0015, 0.0026, 0.0025, 0.0020, 0.0017, 0.0016, 0.0011, 0.0014, 0.0018,\n",
      "        0.0014, 0.0015, 0.0020, 0.0019, 0.0033, 0.0015, 0.0017, 0.0017, 0.0023,\n",
      "        0.0011, 0.0014, 0.0030, 0.0017, 0.0136, 0.0031, 0.0015, 0.0065, 0.0015,\n",
      "        0.0038, 0.0015, 0.0013, 0.0024, 0.0015, 0.0019, 0.0018, 0.0035, 0.0017,\n",
      "        0.0023, 0.0016, 0.0021, 0.0028, 0.0047, 0.0054, 0.0027, 0.0025, 0.0015,\n",
      "        0.0029, 0.0027, 0.0015, 0.0042, 0.0019, 0.0027, 0.0031, 0.0032, 0.0110,\n",
      "        0.0039, 0.0034, 0.0033, 0.0180, 0.0036, 0.0036, 0.0021, 0.0024, 0.0040,\n",
      "        0.0025, 0.0023, 0.0074, 0.0040, 0.0046, 0.0026, 0.0034, 0.0028, 0.0030,\n",
      "        0.0029, 0.0036, 0.0050, 0.0124, 0.0081, 0.0064, 0.0033, 0.0044, 0.0062,\n",
      "        0.0122, 0.0044, 0.0081, 0.0134, 0.0054, 0.0221, 0.0087, 0.0054, 0.0059,\n",
      "        0.0324, 0.0075, 0.0164, 0.0281, 0.0142, 0.0224, 0.0136, 0.0998, 0.0324,\n",
      "        0.0393, 0.0271, 0.0476], dtype=torch.float64)\n",
      "tensor([ 0.0000e+00, 7.0614e-283,  1.5873e-49,  3.7832e-25, 2.2543e-117,\n",
      "        5.0214e-129,  5.0600e-72,  9.4051e-64,  8.3333e-02, 5.6169e-222,\n",
      "        5.9205e-284,  8.3333e-02, 1.7363e-101, 1.7704e-131, 1.2981e-137,\n",
      "        7.5409e-193,  2.7778e-02, 6.9746e-148, 1.5608e-132,  4.5632e-09,\n",
      "        7.5449e-176, 7.9639e-271, 3.7215e-226,  5.0893e-81,  6.8219e-54,\n",
      "         3.9009e-57, 6.9746e-148, 1.5216e-191,  0.0000e+00,  3.9009e-57,\n",
      "        4.9173e-136,  6.5255e-04,  1.8613e-82, 1.3184e-155,  6.5255e-04,\n",
      "         1.8613e-82,  7.5760e-70,  8.2028e-02, 7.1301e-208, 1.5608e-132,\n",
      "        5.8989e-127, 1.3157e-217, 3.5377e-318,  1.8613e-82, 1.0776e-178,\n",
      "        1.6754e-221, 1.2339e-121,  0.0000e+00,  1.8613e-82,  6.6238e-28,\n",
      "        4.5303e-104, 1.3188e-108,  2.7778e-02,  1.6566e-76,  1.6667e-01,\n",
      "        2.0630e-228, 2.2543e-117,  0.0000e+00, 1.0140e-147,  1.1905e-02,\n",
      "         1.6566e-76,  8.3333e-02, 1.5608e-132,  4.5632e-09, 1.6090e-112,\n",
      "        6.9710e-179,  1.6566e-76, 4.1660e-103, 1.6351e-249,  1.1905e-02,\n",
      "         5.5363e-56,  1.1905e-02, 5.6195e-239, 4.2194e-179, 1.2981e-137,\n",
      "        7.6800e-134,  2.7778e-02,  1.6566e-76, 2.1721e-144, 3.7704e-195,\n",
      "        1.6580e-241,  1.8613e-82, 5.4399e-174, 1.3792e-163, 3.0458e-263,\n",
      "        4.9173e-136, 7.5409e-193, 1.5608e-132, 4.5002e-173, 1.2981e-137,\n",
      "        1.7636e-165,  1.8613e-82,  4.5632e-09, 2.2568e-190, 4.2194e-179,\n",
      "         8.3333e-02,  1.6667e-01,  1.8613e-82, 1.7313e-194, 6.5276e-131,\n",
      "         1.8613e-82,  7.5760e-70, 3.2376e-145,  1.8613e-82,  7.5760e-70,\n",
      "         4.5632e-09, 1.6090e-112, 9.9583e-126, 4.2194e-179, 1.2981e-137,\n",
      "         8.3333e-02,  5.9398e-50, 1.5608e-132,  4.5632e-09, 4.1730e-273,\n",
      "        1.2981e-137,  0.0000e+00, 2.9519e-154,  1.1905e-02,  1.6566e-76,\n",
      "        2.3601e-174, 1.5877e-124,  1.8613e-82, 4.8409e-320,  2.2060e-99,\n",
      "         1.6566e-76,  8.3006e-71, 4.2194e-179, 4.0441e-312, 1.5130e-309,\n",
      "         1.1905e-02,  0.0000e+00, 1.5608e-132,  4.5632e-09, 1.6090e-112,\n",
      "        7.0021e-177,  1.1905e-02, 1.2915e-200, 1.0355e-224,  7.5760e-70,\n",
      "         0.0000e+00,  1.1905e-02, 3.7723e-241, 1.5608e-132, 5.8989e-127,\n",
      "        4.9057e-124,  1.0054e-69, 5.3927e-118], dtype=torch.float64)\n",
      "\n",
      "MaxEnt would have predicted the following tokens:\n",
      "1.0000000000000004\n",
      " -> -logP: 9.2209, [ rights], idx = 2489\n",
      " -> -logP: 9.4930, [ most], idx = 749\n",
      " -> -logP: 9.5082, [ Rights], idx = 6923\n",
      " -> -logP: 9.5484, [rights], idx = 28046\n",
      " -> -logP: 9.9099, [ holiest], idx = 47264\n",
      " -> -logP: 9.9289, [ widest], idx = 46232\n",
      " -> -logP: 9.9493, [ biggest], idx = 4094\n",
      " -> -logP: 9.9863, [ greatest], idx = 6000\n",
      " -> -logP: 10.0015, [ humanitarian], idx = 15706\n",
      " -> -logP: 10.0092, [ Most], idx = 4042\n"
     ]
    }
   ],
   "source": [
    "prompt = \"--- - - - ---- - - - ----p''''' -\"\n",
    "prompt = \"The year is 2194, and humanity no longer lives on Earth. After the Collapse, we fled to floating arcologies orbiting the gas giants. Every child knows the stories of our homeworld, but none of us have seen a tree, felt rain, or walked on\"\n",
    "prompt = \"The Great Wall of China is a series of fortifications built to protect ancient Chinese states from invasions. It stretches over 13,000 miles and is one of the most iconic structures in the world. The wall was built over several dynasties, with the earliest sections dating back to the 7th century BC\"\n",
    "prompt = \"DNA, or deoxyribonucleic acid, is the molecule that carries genetic instructions in all living organisms. It is composed of four nucleotide bases: adenine, thymine, cytosine, and guanine. These bases form sequences that determine traits and biological functions. The structure of DNA is a double helix, with two strands winding around each other, held together by complementary base pairing—adenine pairs with thymine, and cytosine with guanine. This configuration ensures accurate replication during cell division. Mutations, or changes in the DNA sequence, can lead to variations in traits, some of which may result in genetic disorders or evolutionary advantages.DNA replication and transcription are essential processes that convert genetic information into proteins, which perform vital structural and functional roles in the body. Understanding DNA has revolutionized fields such as medicine, forensic science, and biotechnology, enabling breakthroughs like gene editing and personalized treatments\"\n",
    "prompt = \"The Mona Lisa is a world-famous painting by Leonardo da Vinci, created in the early 16th century. It is housed in the Louvre Museum in Paris and is known for its enigmatic expression and detailed background. The painting is considered a masterpiece of the Italian Renaissance.\"\n",
    "prompt = \"DNA, or deoxyribonucleic acid, is the molecule that carries genetic instructions in all living organisms. It is composed of four nucleotide bases: adenine, thymine, cytosine, and guanine. These bases form sequences that determine traits and biological functions.\"\n",
    "prompt = \"I'm an Italian physicist who lived in Padua. I am known for my work in the field of optics and astronomy. \" \\\n",
    "        \"I was born in 1564 and died in 1642. My name is Galileo Galilei\"\n",
    "prompt = \"Mount Everest is the tallest mountain on Earth, located in the Himalayas on the border between Nepal and China\"\n",
    "prompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect.\" \\\n",
    "\" I was born in 1879 and died in 1955. My name is Albert Einstein\"\n",
    "prompt = \"The american flag is white, red and blue. The flag has 13 stripes and 50 stars\"\n",
    "prompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I made groundbreaking contributions not only to relativity but also to quantum mechanics, statistical mechanics, and cosmology. \" \\\n",
    "\"My famous equation, E=mc², has become one of the most well-known formulas in the world. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect, which helped establish quantum theory. \" \\\n",
    "\"Throughout my life, I advocated for civil rights, pacifism, and Zionism, and I was known for my humanitarian views. \" \\\n",
    "\"I spent my later years in the United States, working at the Institute for Advanced Study in Princeton. \" \\\n",
    "\"I was born in 1879 and died in 1955. My name is Albert Einstein\"\n",
    "\n",
    "prob, idxs, tokens = GPT2extractPDFLastToken(prompt, 10)\n",
    "print(\"Masking the last token (\\\"\" , ''.join(prompt.split()[-1]), \"\\\"), GPT2 would have predicted:\", sep = \"\")\n",
    "for p, idx, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> -logP = {-torch.log(p):.2f}: ['{token}'], idx = {idx}\")\n",
    "\n",
    "prompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I made groundbreaking contributions not only to relativity but also to quantum mechanics, statistical mechanics, and cosmology. \" \\\n",
    "\"My famous equation, E=mc², has become one of the most well-known formulas in the world. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect, which helped establish quantum theory. \" \\\n",
    "\"Throughout my life, I advocated for civil rights, pacifism, and Zionism, and I was known for my humanitarian views. \" \\\n",
    "\"I spent my later years in the United States, working at the Institute for Advanced Study in Princeton. \" \\\n",
    "\"I was born in 1879 and died in 1955. My name is Albert\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "T = torch.nn.functional.one_hot(inputs.input_ids[0], num_classes=embeddings.shape[0]).float()\n",
    "E = torch.matmul(T,embeddings)\n",
    "E = E / np.linalg.norm(E, axis=1, keepdims=True)  \n",
    "# Let's solve for mu, now that we have the attention vector and the embedding matrix\n",
    "amplificationAttention = 1\n",
    "vectorA, _ = getEA(prompt)\n",
    "mu = solveMu(E, torch.tensor(computeExpectedA(E)), amplificationAttention)\n",
    "Z = computeZ(-E.T @ mu, embeddings)\n",
    "# given mu, we can compute the mean and the mode according to the maxent model\n",
    "x_avg, x_mode = f(E.T @ mu), -E.T @ mu\n",
    "\n",
    "\"\"\"\"\n",
    "print(\"\\nA MaxEnt approach yields:\")\n",
    "print(\"For the mean value (MAXENT):\")\n",
    "prob, idxs, tokens = get_tokens_prob(torch.tensor(x_avg, dtype = torch.float), 5)\n",
    "for p, _, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n",
    "\n",
    "print(\"For the mode value (MAXENT):\")\n",
    "prob, idxs, tokens = get_tokens_prob(torch.tensor(x_mode, dtype = torch.float), 5)\n",
    "for p, _, token in zip(prob, idxs, tokens):\n",
    "    print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n",
    "\"\"\"\n",
    "print(\"\\nMaxEnt would have predicted the following tokens:\")\n",
    "createPDFoverVocabulary(-E.T @ mu, Z, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb82341",
   "metadata": {},
   "source": [
    "Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9aaa97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1:\n",
      "Chosen token:  physicist\n",
      "\n",
      "Iteration 2:\n",
      "Chosen token:  an\n",
      "\n",
      "Iteration 3:\n",
      "Chosen token:  Wonders\n",
      "\n",
      "Iteration 4:\n",
      "Chosen token:  Math\n",
      "\n",
      "Iteration 5:\n",
      "Chosen token: a\n",
      "\n",
      "Iteration 6:\n",
      "Chosen token: retty\n",
      "\n",
      "Iteration 7:\n",
      "Chosen token:  Physics\n",
      "\n",
      "Iteration 8:\n",
      "Chosen token:  Says\n",
      "\n",
      "Iteration 9:\n",
      "Chosen token:  Germans\n",
      "\n",
      "Iteration 10:\n",
      "Chosen token:  Germans\n",
      "I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect. I was born in 1879 and died in 1955. My name is Albert physicist an Wonders Matharetty Physics Says Germans Germans\n"
     ]
    }
   ],
   "source": [
    "initialPrompt = \"I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. \" \\\n",
    "\"I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect.\" \\\n",
    "\" I was born in 1879 and died in 1955. My name is Albert\"\n",
    "\n",
    "for t in range(10):\n",
    "    print(f\"\\nIteration {t+1}:\")\n",
    "    inputs = tokenizer(initialPrompt, return_tensors=\"pt\")\n",
    "    T = torch.nn.functional.one_hot(inputs.input_ids[0], num_classes=embeddings.shape[0]).float()\n",
    "    E = torch.matmul(T,embeddings)\n",
    "    E = E / np.linalg.norm(E, axis=1, keepdims=True)  \n",
    "    # Let's solve for mu, now that we have the attention vector and the embedding matrix\n",
    "    amplificationAttention = 1\n",
    "    mu = solveMu(E, torch.tensor(computeExpectedA(E)), amplificationAttention)\n",
    "    Z = computeZ(-E.T @ mu, embeddings)\n",
    "\n",
    "    logProb = np.zeros(len(embeddings))\n",
    "    for i,tkn in enumerate(embeddings):\n",
    "        dot_product = np.dot(tkn, -E.T @ mu)\n",
    "        logProb[i] = -dot_product + np.log(Z)\n",
    "    sorted_indices = np.argsort(logProb)[:20]\n",
    "    \n",
    "    id_to_token = {v: k for k, v in tokenizer.encoder.items()}\n",
    "    for j in range(10):\n",
    "        decoded_token = tokenizer.decode([sorted_indices[j]])\n",
    "        #print(f\" -> -logP: { logProb[sorted_indices[j]]:.4f}, [{decoded_token}], idx = {sorted_indices[j]}\")\n",
    "\n",
    "    top_k = 10\n",
    "    sorted_indices = np.argsort(logProb)[:top_k] \n",
    "    temperature = 1\n",
    "\n",
    "    # Calcola probabilità con temperatura\n",
    "    top_log_probs = torch.tensor(logProb[sorted_indices])\n",
    "    adjusted_logits = -top_log_probs / temperature\n",
    "    top_probs = torch.softmax(adjusted_logits, dim=0)\n",
    "    sampled_relative_index = torch.multinomial(top_probs, num_samples=1).item()\n",
    "    sampled_token_id = sorted_indices[sampled_relative_index]\n",
    "    decoded_token = tokenizer.decode([sampled_token_id])\n",
    "\n",
    "    print(\"Chosen token:\", decoded_token)\n",
    "    initialPrompt += decoded_token\n",
    "print(initialPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08316665",
   "metadata": {},
   "source": [
    "----\n",
    "Let's explore a bit the linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d88ab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det(G) is:  0.0\n",
      "Given prompt: \" I'm a German-born theoretical physicist who revolutionized modern physics with my theory of relativity. I was awarded the Nobel Prize in Physics in 1921 for my explanation of the photoelectric effect. I was born in 1879 and died in 1955. My name is Albert \"\n",
      "Correct next token:  Einstein\n",
      "\n",
      "Expected value (MAXENT):\n",
      " -> 6.66: ' mathemat'\n",
      " -> 8.02: ' advoc'\n",
      " -> 8.09: ' nodd'\n",
      " -> 8.15: ' distingu'\n",
      " -> 8.15: ' horizont'\n",
      " -> 8.16: ' defic'\n",
      " -> 8.19: ' challeng'\n",
      " -> 8.19: ' rul'\n",
      " -> 8.21: ' confir'\n",
      " -> 8.26: ' trave'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6315/2595120468.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prob, idxs, tokens = get_tokens_prob(torch.tensor(x_avg, dtype = torch.float), 10)\n"
     ]
    }
   ],
   "source": [
    "# Gram matrix\n",
    "G = E @ E.T\n",
    "print(\"The det(G) is: \", np.linalg.det(G))\n",
    "# if zero, just get rid of the double rows? attention should be the same\n",
    "\n",
    "if (np.linalg.matrix_rank(G) == G.shape[0]):\n",
    "    mu_linear = np.linalg.solve(G, -3.*vectorA)\n",
    "    x_avg, x_mode = E.T @ vectorA.float(), E.T @ mu_linear\n",
    "\n",
    "    print(\"Given prompt: \\\"\", ' '.join(prompt.split()[:-1]), \"\\\"\")\n",
    "    print(\"Correct next token: \", ''.join(prompt.split()[-1]))\n",
    "    print(\"\\nExpected value (MAXENT):\")\n",
    "    prob, idxs, tokens = get_tokens_prob(torch.tensor(x_avg, dtype = torch.float), 10)\n",
    "    for p, _, token in zip(prob, idxs, tokens):\n",
    "        print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n",
    "\n",
    "    print(\"Mode value (MAXENT):\")\n",
    "    prob, idxs, tokens = get_tokens_prob(torch.tensor(x_mode, dtype = torch.float), 8)\n",
    "    for p, _, token in zip(prob, idxs, tokens):\n",
    "        print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n",
    "\n",
    "    expectedA = E @ x_avg\n",
    "    #print( \"\\n\\nError on A: \", (expectedA/amplificationAttention - vectorA)/vectorA, \"\\n\\n\")\n",
    "else:\n",
    "    x_avg = E.T @ vectorA.float()\n",
    "    print(\"Given prompt: \\\"\", ' '.join(prompt.split()[:-1]), \"\\\"\")\n",
    "    print(\"Correct next token: \", ''.join(prompt.split()[-1]))\n",
    "    print(\"\\nExpected value (MAXENT):\")\n",
    "    prob, idxs, tokens = get_tokens_prob(torch.tensor(x_avg, dtype = torch.float), 10)\n",
    "    for p, _, token in zip(prob, idxs, tokens):\n",
    "        print(f\" -> {-torch.log(p):.2f}: '{token}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envLabComp + preload)",
   "language": "python",
   "name": "envLabCompWrapped"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
